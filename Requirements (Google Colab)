Please run the commands in the provided order to avoid version conflicts. 

!pip install transformers torch umap-learn bertopic # Install the Transformers library from Hugging Face (provides pretrained language models like BERT, GPT, T5, etc.)

# RESTART THE SESSION

from transformers import AutoTokenizer, AutoModel # allow to load any compatible pretrained model or tokenizer by name
tokenizer = AutoTokenizer.from_pretrained("emilyalsentzer/Bio_ClinicalBERT") # Loads the tokenizer specifically configured for Bio_ClinicalBERT
model = AutoModel.from_pretrained("emilyalsentzer/Bio_ClinicalBERT") # Loads the encoder-only model (BERT) for generating contextual embeddings

import pandas as pd
import numpy as np
import re # module for pattern matching and text manipulation
import torch # PyTorch library for deep learning
from bertopic import BERTopic
pd.options.display.max_colwidth = 15000
pd.options.display.max_rows = 100

# to import the data file
from google.colab import drive 
drive.mount('/content/drive')

# Due to the human research rules, the MIMIC-III database files cannot be publicly provided. 
path = "/content/drive/MyDrive/Data/discharge.csv.gz"
text_access = "text"



