{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L4QJ78n2KeJy"
      },
      "source": [
        "# **Full Loop (1 hour)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-jihee7OLvpz",
        "outputId": "64a67212-04bf-422f-fe32-85604b065b5c"
      },
      "outputs": [],
      "source": [
        "batch_size = 100 # BERT models are heavy (took over an hour!). Instead of processing all rows at once (which would crash Colab), we work in chunks of 100.\n",
        "all_embeddings = [] # list to store embeddings\n",
        "texts = lda_2k[\"exp_text\"].tolist()\n",
        "\n",
        "for i in range(0, len(texts), batch_size):\n",
        "    batch_texts = texts[i:i + batch_size]\n",
        "    tokenized = tokenizer(\n",
        "        batch_texts,\n",
        "        padding=True,\n",
        "        truncation=True,\n",
        "        max_length=512,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "    with torch.no_grad(): # Disables gradient tracking with torch.no_grad() to save on computing resources\n",
        "        outputs = model(**tokenized) # Runs the tokenized batch through the BERT model but in a very efficient way, specifically for inference, not training.\n",
        "\n",
        "    # Mean pooling\n",
        "    attention_mask = tokenized[\"attention_mask\"].unsqueeze(-1)\n",
        "    masked = outputs.last_hidden_state * attention_mask\n",
        "    embeddings = masked.sum(dim=1) / attention_mask.sum(dim=1)\n",
        "\n",
        "    all_embeddings.extend(embeddings.cpu().numpy().tolist())\n",
        "\n",
        "lda_2k[\"bert_embedding\"] = all_embeddings\n",
        "# This column will contain:\n",
        "# One 768-dimensional vector per clinical note\n",
        "# Stored as a list of floats.\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
